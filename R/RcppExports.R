# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' @title Gibbs Sampler for a Binomial-Beta Model
#' @description This function performs Gibbs sampling for a Binomial-Beta hierarchical model. 
#' It generates samples from the joint posterior distribution of \code{x} and \code{y}.
#' @param n_iter An integer specifying the number of iterations for the Gibbs sampler.
#' @param n An integer representing the total number of trials for the Binomial distribution.
#' @param a A numeric value specifying the shape parameter \code{a} of the Beta prior.
#' @param b A numeric value specifying the shape parameter \code{b} of the Beta prior.
#' @return A numeric matrix of size \code{n_iter} x 2 where each row contains a sample of \code{x} (column 1) and \code{y} (column 2).
#' @details 
#' The Gibbs sampler alternates between two steps:
#' \itemize{
#'   \item Sampling \code{x} given \code{y} from a Binomial distribution with parameters \code{n} and \code{y}.
#'   \item Sampling \code{y} given \code{x} from a Beta distribution with parameters \code{x + a} and \code{n - x + b}.
#' }
#' This procedure approximates the joint posterior distribution of \code{x} and \code{y}.
#' @examples
#' \dontrun{
#' n_iter <- 1000
#' n <- 10
#' a <- 2
#' b <- 2
#' samples <- gibbs_sampler(n_iter, n, a, b)
#' plot(samples[,1], samples[,2], main = "Gibbs Sampler", xlab = "x", ylab = "y")
#' }
#' @export
#' @useDynLib SA24204158, .registration = TRUE
gibbs_sampler <- function(n_iter, n, a, b) {
    .Call(`_SA24204158_gibbs_sampler`, n_iter, n, a, b)
}

#' @title DNN Classifier
#' @description A DNN implementation using Rcpp
#' @param train_data A numeric matrix where rows are training samples and columns are features
#' @param train_labels An integer vector representing labels for the training data
#' @param test_data A numeric matrix where rows are test samples and columns are features
#' @param s An integer specifying the number of nearest neighbors to consider for the weighted sum
#' @return An integer vector containing the predicted labels for the test samples
#' @examples
#' \dontrun{
#' train_data <- matrix(c(1, 2, 1, 3, 4, 5, 6, 7), ncol = 2)
#' train_labels <- c(0, 0, 1, 1)
#' test_data <- matrix(c(1.5, 2.5, 6, 7), ncol = 2)
#' predictions <- dnnC(train_data, train_labels, test_data, s = 3)
#' print(predictions)
#' }
#' @export
#' @useDynLib SA24204158, .registration = TRUE  
dnnC <- function(train_data, train_labels, test_data, s) {
    .Call(`_SA24204158_dnnC`, train_data, train_labels, test_data, s)
}

#' @title DNN Classifier with Cross-Validation
#' @description A DNN implementation that selects the best s using 5-fold cross-validation
#' @param train_data A numeric matrix where rows are training samples and columns are features
#' @param train_labels An integer vector representing labels for the training data
#' @param s_values A vector of integers representing the candidate values of s for cross-validation
#' @return The optimal s value that maximizes the average cross-validation accuracy
#' @examples
#' \dontrun{
#' train_data <- matrix(rnorm(200 * 2), ncol = 2)
#' train_labels <- sample(c(0, 1), size = 200, replace = TRUE)
#' s_values <- c(1, 2, 3, 4, 5)
#' best_s <- dnnCvC(train_data, train_labels, s_values)
#' print(best_s)
#' }
#' @export
#' @useDynLib SA24204158, .registration = TRUE 
dnnCvC <- function(train_data, train_labels, s_values) {
    .Call(`_SA24204158_dnnCvC`, train_data, train_labels, s_values)
}

#' @title TDNN Classifier
#' @description A TDNN implementation using Rcpp
#' @param train_data A numeric matrix where rows are training samples and columns are features
#' @param train_labels An integer vector representing labels for the training data
#' @param test_data A numeric matrix where rows are test samples and columns are features
#' @param s1 An integer specifying the first subsample size
#' @param s2 An integer specifying the second subsample size
#' @return An integer vector containing the predicted labels for the test samples
#' @examples
#' \dontrun{
#' train_data <- matrix(c(1, 2, 1, 3, 4, 5, 6, 7), ncol = 2)
#' train_labels <- c(0, 0, 1, 1)
#' test_data <- matrix(c(1.5, 2.5, 6, 7), ncol = 2)
#' predictions <- tdnnC(train_data, train_labels, test_data, s1 = 3, s2 = 5)
#' print(predictions)
#' }
#' @export
#' @useDynLib SA24204158, .registration = TRUE  
tdnnC <- function(train_data, train_labels, test_data, s1, s2) {
    .Call(`_SA24204158_tdnnC`, train_data, train_labels, test_data, s1, s2)
}

#' @title TDNN Classifier with Cross-Validation for s2
#' @description A TDNN implementation that selects the best s2 using 5-fold cross-validation, with s1 = 2 * s2
#' @param train_data A numeric matrix where rows are training samples and columns are features
#' @param train_labels An integer vector representing labels for the training data
#' @param s2_values A vector of integers representing the candidate values of s2 for cross-validation
#' @param c A scalar parameter that defines the relationship between s1 and s2. Specifically, s1 = c * s2. 
#' @return The optimal s2 value that maximizes the average cross-validation accuracy
#' @examples
#' \dontrun{
#' train_data <- matrix(rnorm(200 * 2), ncol = 2)
#' train_labels <- sample(c(0, 1), size = 200, replace = TRUE)
#' s2_values <- c(1, 2, 3, 4, 5)
#' best_s2 <- tdnnCvC(train_data, train_labels, s2_values)
#' print(best_s2)
#' }
#' @export
#' @useDynLib SA24204158, .registration = TRUE 
tdnnCvC <- function(train_data, train_labels, s2_values, c) {
    .Call(`_SA24204158_tdnnCvC`, train_data, train_labels, s2_values, c)
}

#' @title K-Nearest Neighbors Classifier
#' @description A simple KNN implementation using Rcpp
#' @param train_data A numeric matrix where rows are training samples and columns are features
#' @param train_labels An integer vector representing labels for the training data
#' @param test_data A numeric matrix where rows are test samples and columns are features
#' @param k An integer specifying the number of nearest neighbors to consider
#' @return An integer vector containing the predicted labels for the test samples
#' @examples
#' \dontrun{
#' train_data <- matrix(c(1, 2, 1, 3, 4, 5, 6, 7), ncol = 2)
#' train_labels <- c(0, 0, 1, 1)
#' test_data <- matrix(c(1.5, 2.5, 6, 7), ncol = 2)
#' predictions <- knnC(train_data, train_labels, test_data, k = 3) 
#' print(predictions)
#' }
#' @export
#' @useDynLib SA24204158, .registration = TRUE  
knnC <- function(train_data, train_labels, test_data, k) {
    .Call(`_SA24204158_knnC`, train_data, train_labels, test_data, k)
}

#' @title K-Nearest Neighbors Classifier with Cross-Validation
#' @description A KNN implementation that selects the best K using 5-fold cross-validation
#' @param train_data A numeric matrix where rows are training samples and columns are features
#' @param train_labels An integer vector representing labels for the training data
#' @param k_values A vector of integers representing the candidate values of k for cross-validation
#' @return The optimal k value that maximizes the average cross-validation accuracy
#' @examples
#' \dontrun{
#' train_data <- matrix(rnorm(200 * 2), ncol = 2)
#' train_labels <- sample(c(0, 1), size = 200, replace = TRUE)
#' k_values <- c(1, 2,3,4,5)
#' best_k <- knnCvC(train_data, train_labels, k_values)
#' print(best_k)
#' }
#' @export
#' @useDynLib SA24204158, .registration = TRUE 
knnCvC <- function(train_data, train_labels, k_values) {
    .Call(`_SA24204158_knnCvC`, train_data, train_labels, k_values)
}

